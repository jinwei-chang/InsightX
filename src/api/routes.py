from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from src.services.scraper_service import ScraperService
from src.services.llm_service import LLMService
from src.config.mock_responses import get_mock_response
import json

router = APIRouter()
scraper = ScraperService()
llm = LLMService()

# Use mock responses for demo (since Gemini API quota is exceeded)
USE_MOCK_RESPONSES = True

class AnalyzeRequest(BaseModel):
    url: str

class ReplyRequest(BaseModel):
    topic: str

class MarketingRequest(BaseModel):
    strengths: str

class WeeklyPlanRequest(BaseModel):
    weaknesses: str

class TrainingScriptRequest(BaseModel):
    issue: str

class InternalEmailRequest(BaseModel):
    strengths: str
    weaknesses: str

class ChatRequest(BaseModel):
    message: str

@router.post("/analyze")
async def analyze(request: AnalyzeRequest):
    try:
        print(f"[INFO] æ”¶åˆ°åˆ†æè«‹æ±‚: {request.url}")
        
        # TODO: æš«æ™‚è·³éçœŸå¯¦çˆ¬èŸ²ï¼Œç›´æ¥è¿”å› Mock æ•¸æ“š
        # åŸå› ï¼šçˆ¬èŸ²å¯èƒ½å¤ªæ…¢æˆ–æœ‰å…¶ä»–å•é¡Œå°è‡´ 500 éŒ¯èª¤
        print("[INFO] ä½¿ç”¨ Mock æ•¸æ“šï¼ˆè·³éçˆ¬èŸ²æ­¥é©Ÿï¼‰")
        
        mock_analysis = {
            "platform": "google",
            "total_reviews": "å…±åˆ†æ 723 å‰‡ Google Maps è©•è«–",
            "good": [
                {"label": "é¤é»ç¾å‘³", "value": 32},
                {"label": "ç’°å¢ƒèˆ’é©", "value": 25},
                {"label": "æœå‹™è¦ªåˆ‡", "value": 20}
            ],
            "bad": [
                {"label": "å‡ºé¤é€Ÿåº¦æ…¢", "value": 40},
                {"label": "åœè»Šä¸æ–¹ä¾¿", "value": 18},
                {"label": "åƒ¹æ ¼åé«˜", "value": 12}
            ]
        }
        
        print("[SUCCESS] Mock åˆ†æå®Œæˆï¼Œè¿”å›çµæœ")
        return mock_analysis
            
    except HTTPException as he:
        raise he
    except Exception as e:
        import traceback
        print(f"[ERROR] ç™¼ç”ŸéŒ¯èª¤:")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±æ•—: {str(e)}")

@router.post("/reply")
async def generate_reply(request: ReplyRequest):
    """ç”Ÿæˆå°è² é¢è©•è«–çš„å›è¦†"""
    if USE_MOCK_RESPONSES:
        reply = get_mock_response("reply_to_complaint", topic=request.topic)
    else:
        reply = await llm.generate_reply(request.topic)
    return {"reply": reply}

@router.post("/analyze-issue")
async def analyze_issue(request: ReplyRequest):
    """æ ¹æºå•é¡Œåˆ†æ"""
    if USE_MOCK_RESPONSES:
        analysis = get_mock_response("root_cause_analysis", topic=request.topic)
    else:
        # Call LLM with root cause analysis prompt
        analysis = await llm.generate_root_cause_analysis(request.topic)
    return {"analysis": analysis}

@router.post("/marketing")
async def generate_marketing(request: MarketingRequest):
    """ç”Ÿæˆ FB/IG è¡ŒéŠ·è²¼æ–‡"""
    if USE_MOCK_RESPONSES:
        copy = get_mock_response("marketing_copy", strengths=request.strengths)
    else:
        copy = await llm.generate_marketing(request.strengths)
    return {"copy": copy}

@router.post("/weekly-plan")
async def generate_weekly_plan(request: WeeklyPlanRequest):
    """ç”Ÿæˆé€±è¡Œå‹•è¨ˆç•«"""
    if USE_MOCK_RESPONSES:
        plan = get_mock_response("weekly_plan", weaknesses=request.weaknesses)
    else:
        plan = await llm.generate_weekly_plan(request.weaknesses)
    return {"plan": plan}

@router.post("/training-script")
async def generate_training_script(request: TrainingScriptRequest):
    """ç”Ÿæˆå“¡å·¥åŸ¹è¨“åŠ‡æœ¬"""
    if USE_MOCK_RESPONSES:
        script = get_mock_response("training_script", issue=request.issue)
    else:
        script = await llm.generate_training_script(request.issue)
    return {"script": script}

@router.post("/internal-email")
async def generate_internal_email(request: InternalEmailRequest):
    """ç”Ÿæˆå…§éƒ¨å…¬å‘Šä¿¡"""
    if USE_MOCK_RESPONSES:
        email = get_mock_response("internal_email", 
                                 strengths=request.strengths,
                                 weaknesses=request.weaknesses)
    else:
        email = await llm.generate_internal_email(request.strengths, request.weaknesses)
    return {"email": email}

@router.post("/chat")
async def chat(request: ChatRequest):
    """AI èŠå¤©åŠ©æ‰‹"""
    try:
        if USE_MOCK_RESPONSES:
            # æ™ºèƒ½ Mock å›æ‡‰ï¼ˆæ ¹æ“šå•é¡Œå…§å®¹ï¼‰
            message = request.message.lower()
            
            if any(word in message for word in ['å‡ºé¤', 'é€Ÿåº¦', 'æ…¢', 'ç­‰å¾…']):
                reply = """æ ¹æ“šåˆ†æå ±å‘Šï¼Œ**å‡ºé¤é€Ÿåº¦æ…¢**æ˜¯ä¸»è¦ç—›é»ï¼ˆ40%ï¼‰ã€‚

å»ºè­°æ”¹å–„æ–¹æ¡ˆï¼š
1. **çŸ­æœŸ**ï¼šå¢åŠ å°–å³°æ™‚æ®µäººæ‰‹
2. **ä¸­æœŸ**ï¼šå„ªåŒ–å»šæˆ¿ SOPæµç¨‹
3. **é•·æœŸ**ï¼šå¼•å…¥å»šæˆ¿ç®¡ç†ç³»çµ±

åƒè€ƒé€±è¡Œå‹•è¨ˆç•«ä¸­çš„ã€Œæµç¨‹å„ªåŒ–Weekã€é€²è¡Œæ”¹å–„ã€‚"""
                
            elif any(word in message for word in ['åœè»Š', 'è»Šä½', 'ä¸æ–¹ä¾¿']):
                reply = """é‡å°**åœè»Šä¸æ–¹ä¾¿**å•é¡Œï¼ˆ18%ï¼‰ï¼Œå»ºè­°ï¼š

âœ… èˆ‡é„°è¿‘åœè»Šå ´æ´½è«‡åˆä½œ
âœ… æä¾›ä»£å®¢æ³Šè»Šæœå‹™
âœ… åœ¨ Google Maps æ¨™è¨»é™„è¿‘åœè»Šè³‡è¨Š
âœ… æ¨å»£å¤–é€æœå‹™ä½œç‚ºæ›¿ä»£æ–¹æ¡ˆ"""
                
            elif any(word in message for word in ['åƒ¹æ ¼', 'è²´', 'ä¾¿å®œ', 'åˆ’ç®—']):
                reply = """**åƒ¹æ ¼åé«˜**ï¼ˆ12%ï¼‰çš„ç­–ç•¥å»ºè­°ï¼š

ğŸ’¡ ä¸å»ºè­°ç›´æ¥é™åƒ¹ï¼Œè€Œæ˜¯ï¼š
- æ¨å‡ºã€Œè¶…å€¼å¥—é¤ã€å¢åŠ CPå€¼æ„Ÿå—
- å¼·åŒ–é¤é»è³ªæ„Ÿèˆ‡æœå‹™é«”é©—
- æœƒå“¡åˆ¶åº¦æä¾›å°ˆå±¬å„ªæƒ 
- é€éè¡ŒéŠ·çªå‡ºã€Œç‰©æœ‰æ‰€å€¼ã€"""
                
            elif any(word in message for word in ['è¡ŒéŠ·', 'å®£å‚³', 'æ¨å»£', 'ç¤¾ç¾¤']):
                reply = """ç¤¾ç¾¤è¡ŒéŠ·å»ºè­°ï¼š

ğŸ“± **Facebook/Instagram**ï¼š
- åˆ©ç”¨ã€Œé¤é»ç¾å‘³ã€å„ªå‹¢ï¼ˆ32%å¥½è©•ï¼‰
- åˆ†äº«æ–™ç†éç¨‹èˆ‡é£Ÿææ•…äº‹
- é¡§å®¢å¥½è©•æˆªåœ–åˆ†äº«
- é™æ™‚å„ªæƒ æ´»å‹•

åƒè€ƒã€Œåˆ©ç”¨å„ªé»ç”ŸæˆFB/IGè¡ŒéŠ·è²¼æ–‡ã€åŠŸèƒ½ç”Ÿæˆå…§å®¹ï¼"""
                
            elif any(word in message for word in ['å“¡å·¥', 'åŸ¹è¨“', 'è¨“ç·´', 'æœå‹™']):
                reply = """å“¡å·¥åŸ¹è¨“é‡é»ï¼š

ğŸ‘¥ **æœå‹™è¦ªåˆ‡**å·²ç²20%å¥½è©•ï¼Œè«‹ç¹¼çºŒä¿æŒï¼

é‡å°å‡ºé¤æ…¢å•é¡Œï¼Œè«‹ä½¿ç”¨ã€Œç”¢ç”ŸåŠ‡æœ¬ã€åŠŸèƒ½ï¼š
- å­¸ç¿’æ­£ç¢ºæ‡‰å°è©±è¡“
- é¿å… NG å›æ‡‰
- æå‡é¡§å®¢æ»¿æ„åº¦"""
                
            else:
                reply = f"""æ‚¨å¥½ï¼æˆ‘æ˜¯ AI ç­–ç•¥é¡§å• ğŸ¤–

æ‚¨è©¢å•ï¼šã€Œ{request.message}ã€

æˆ‘å¯ä»¥å”åŠ©æ‚¨ï¼š
âœ… åˆ†æé¡§å®¢å›é¥‹æ•¸æ“š
âœ… æä¾›æ”¹å–„å»ºè­°
âœ… è¡ŒéŠ·ç­–ç•¥è¦åŠƒ
âœ… å“¡å·¥åŸ¹è¨“æ–¹æ¡ˆ

è«‹åƒè€ƒåˆ†æå ±å‘Šä¸­çš„è©³ç´°æ•¸æ“šï¼Œæˆ–ä½¿ç”¨é é¢ä¸Šçš„å„é … AI å·¥å…·ï¼"""
        else:
            reply = await llm.chat(request.message)
        return {"reply": reply}
    except Exception as e:
        return {"reply": "æŠ±æ­‰ï¼ŒAI åŠ©æ‰‹æš«æ™‚ç„¡æ³•å›æ‡‰ã€‚è«‹ç¨å¾Œå†è©¦ã€‚"}

